{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_tagging_CNN_Submission_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RopkhmcAzrgi"
      },
      "source": [
        "import tensorflow.compat.v1 as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgG0X6N8UXQF"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3rEMVNi3ehP"
      },
      "source": [
        "from tensorflow.keras.callbacks import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T0k4IePAI6B"
      },
      "source": [
        "def readAudio(filename):\n",
        "    x, sr = librosa.load(filename, sr=16000)\n",
        "    return x, sr\n",
        "\n",
        "#calculate spectrogram\n",
        "def calc_spec(x):\n",
        "    n_fft = 1024\n",
        "    hop_length = 512\n",
        "    win_length = 1024\n",
        "    X = np.abs(librosa.stft(x, n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann', dtype = np.complex256))\n",
        "    X = librosa.power_to_db(X**2,ref=np.max)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVUaSmBVVEbv"
      },
      "source": [
        "import librosa\n",
        "def get_feature_matrix(audio_filename_path):  \n",
        "    \"\"\"Extract acoustic features (log mel-energies) for given audio file and store them.\"\"\"\n",
        "    \n",
        "    audio, fs = librosa.load(audio_filename_path)\n",
        "    hop_len = 0.02\n",
        "    mel_extractor = dcase_util.features.MelExtractor(n_mels=40, win_length_seconds=0.04, hop_length_seconds=hop_len, fs = fs)\n",
        "    mel_data = mel_extractor.extract(y=audio)\n",
        "    #numpy.save(feature_filename, mel_data)\n",
        "    return mel_data, hop_len\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOaB_dO3BxhG"
      },
      "source": [
        "import librosa\n",
        "def get_feature_matrix_script_features(audio_filename_path):  \n",
        "    \"\"\"Extract acoustic features (log mel-energies) for given audio file and store them.\"\"\"\n",
        "    audio, fs = librosa.load(audio_filename_path, sr = 16000)\n",
        "    mel_data = calc_spec(audio)\n",
        "\n",
        "    return mel_data, 10/mel_data.shape[1]\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB1n9eU7ExtL"
      },
      "source": [
        "def csv_to_meta_container(csv_file_path):\n",
        "  dict_container = dcase_util.containers.ListDictContainer(filename = csv_file_path)\n",
        "  dict_container.load()\n",
        "  train_meta = dcase_util.containers.MetaDataContainer(dict_container)\n",
        "  print(train_meta)\n",
        "  return train_meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dDLfHr1YKce"
      },
      "source": [
        "train_meta = csv_to_meta_container('/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project/dataset_updated/labels_updated.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__qW67yPyypJ"
      },
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "audio_folder_name = '/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project/dataset_updated/wav_updated'\n",
        "for audio_filename in os.listdir(audio_folder_name)[:3]:#os.listdir() s1.wav, s2.wav\n",
        "    #print('Load', db.absolute_to_relative_path(audio_filename))\n",
        "    \n",
        "    # Extract features, load them from file if they exists, if not extract and save\n",
        "    audio_path = os.path.join(audio_folder_name, audio_filename)\n",
        "    features, hop_length_seconds = get_feature_matrix_script_features(audio_path)\n",
        "\n",
        "    # Targets\n",
        "    event_list = train_meta.filter(filename=audio_filename.split('.')[0])\n",
        "    labels_ = np.zeros(2)\n",
        "    for event in event_list:\n",
        "      if(event.event_label == 'music'):\n",
        "        labels_[1] = 1\n",
        "      elif(event.event_label == 'speech'):\n",
        "        labels_[0] = 1\n",
        "    \n",
        "    X_train.append(features) \n",
        "    Y_train.append(labels_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmTE5wIAsPx5"
      },
      "source": [
        "X_train = np.stack(X_train)\n",
        "Y_train = np.stack(Y_train)\n",
        "#Y_train = np.moveaxis(Y_train, 1, 2)\n",
        "print('----------------------')\n",
        "print('X_train shape', X_train.shape)\n",
        "print('Y_train shape', Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDkTabiyCEJ1"
      },
      "source": [
        "import numpy as np\n",
        "def load_features_and_labels(features_path, labels_path):\n",
        "  X = np.load(features_path)\n",
        "  Y = np.load(labels_path)\n",
        "  return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tC2d-bqFThQ"
      },
      "source": [
        "validation_meta = csv_to_meta_container('/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project/dataset_updated/labels_updated.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcvBQP2ayypJ"
      },
      "source": [
        "X_validation = []\n",
        "Y_validation = []\n",
        "validation_data = {}\n",
        "audio_folder_name = '/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project/validation_data/validation_wavs'\n",
        "for audio_filename in os.listdir(audio_folder_name):#os.listdir() s1.wav, s2.wav\n",
        "    \n",
        "    # Extract features, load them from file if they exists, if not extract and save\n",
        "    audio_path = os.path.join(audio_folder_name, audio_filename)\n",
        "    features, hop_length_seconds = get_feature_matrix_script_features(audio_path)\n",
        "    features = features[:,:500] \n",
        "\n",
        "    # Targets\n",
        "    event_list = validation_meta.filter(filename=audio_filename.split('.')[0])\n",
        "    labels_ = np.zeros(2)\n",
        "    for event in event_list:\n",
        "      if(event.event_label == 'music'):\n",
        "        labels_[1] = 1\n",
        "      elif(event.event_label == 'speech'):\n",
        "        labels_[0] = 1\n",
        "\n",
        "\n",
        "    X_validation.append(features) \n",
        "    Y_validation.append(labels_)\n",
        "\n",
        "    validation_data[audio_filename] = {\n",
        "        'features' : features,\n",
        "        'ground_truth' : labels_\n",
        "    }\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygjb83Q1sta2"
      },
      "source": [
        "X_validation = np.stack(X_validation)\n",
        "Y_validation = np.stack(Y_validation)\n",
        "#Y_validation = np.moveaxis(Y_validation, 1, 2)\n",
        "print('----------------------')\n",
        "print('X_validation shape', X_validation.shape)\n",
        "print('Y_validation shape', Y_validation.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2hb5_24yypM"
      },
      "source": [
        "Next we create **CRNN** styled neural network structure layer by layer\n",
        "\n",
        "\n",
        "**Input** layer and **Reshaping** layer to add channel axis into input to match `channels_last` mode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8SaisbnyypM"
      },
      "source": [
        "feature_vector_length = 513   # Number of mel bands\n",
        "sequence_length = 313"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EwR43m6iqFg",
        "outputId": "64581637-1630-4bd2-bec0-ca1eb2646d79"
      },
      "source": [
        "print(feature_vector_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnGgVabdyypM"
      },
      "source": [
        "input_layer = Input(\n",
        "    shape=(feature_vector_length, sequence_length), \n",
        "    name='Input'\n",
        ")\n",
        "x = Reshape(\n",
        "    target_shape=(feature_vector_length, sequence_length, 1), \n",
        "    name='Input_Reshape'\n",
        ")(input_layer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UINpAvQlyypN",
        "outputId": "cd9e6ced-e707-4edc-f14e-5aea30eba563"
      },
      "source": [
        "print('Output shape','(sequence, frequency, time, channel)', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (sequence, frequency, time, channel) (None, 513, 313, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTIKZAQZyypN"
      },
      "source": [
        "**Two convolutional groups** are used to capture small shifts in time and frequency. \n",
        "\n",
        "Similar groups as in sound classification example, except max **pooling done only along frequency** axis as time axis is retained for the detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3ag5KXiyypN",
        "outputId": "716bfde3-dc34-4008-c1ed-d7de9df8b1ea"
      },
      "source": [
        "print('Input shape','(sequence, frequency, time, channel)', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape (sequence, frequency, time, channel) (None, 513, 313, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX-xqaR9yypO"
      },
      "source": [
        "# Convolution\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='linear', kernel_initializer='random_normal',\n",
        "           padding='same', data_format='channels_last', name='Conv1')(x)\n",
        "# Batch normalization\n",
        "x = BatchNormalization(axis=-1, name='Conv1_BatchNorm')(x)\n",
        "# Activation\n",
        "x = Activation(activation='relu', name='Conv1_Activation')(x)\n",
        "# Max pooling along frequency axis\n",
        "x = MaxPooling2D(pool_size=(5, 1), name='Conv1_Pooling')(x)\n",
        "# Drop out\n",
        "x = Dropout(rate=0.2, name='Conv1_DropOut')(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1hYhupByypO",
        "outputId": "0b1cdf0d-74e0-4657-942f-bcbcecfc9ce9"
      },
      "source": [
        "print('Output shape', '(sequence, frequency, time, feature)', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (sequence, frequency, time, feature) (None, 102, 313, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0img3J9yypO",
        "outputId": "a5860fc9-f60b-4329-ec42-1fa8e4a336a0"
      },
      "source": [
        "print('Input shape','(sequence, frequency, time, channel)', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape (sequence, frequency, time, channel) (None, 102, 313, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gBfPxeyypO"
      },
      "source": [
        "# Convolution\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='linear', kernel_initializer='random_normal',\n",
        "           padding='same', data_format='channels_last', name='Conv2')(x)\n",
        "# Batch normalization\n",
        "x = BatchNormalization(axis=-1, name='Conv2_BatchNorm')(x)\n",
        "# Activation\n",
        "x = Activation(activation='relu', name='Conv2_Activation')(x)\n",
        "# Max pooling along frequency axis\n",
        "x = MaxPooling2D(pool_size=(4, 1), name='Conv2_Pooling')(x)\n",
        "# Drop out\n",
        "x = Dropout(rate=0.2, name='Conv2_DropOut')(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y15C_GKRyypP",
        "outputId": "cfc17295-6883-46d0-fd0d-4d98b84c4f93"
      },
      "source": [
        "print('Output shape', '(sequence, frequency, time, feature)', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (sequence, frequency, time, feature) (None, 25, 313, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-aB39aCyypP"
      },
      "source": [
        "To **connect** convolutional layers and recurrent layers, output of the last convolutional group has to be  **Reordered** and **Reshaped**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c9BsGfqyypP",
        "outputId": "5f0584e4-76c2-4786-e211-025ea371d324"
      },
      "source": [
        "print('Input shape', '(sequence, frequency, time, feature)', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape (sequence, frequency, time, feature) (None, 25, 313, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJkwQ6AWyypP"
      },
      "source": [
        "x = Permute(\n",
        "    dims=(1, 3, 2), \n",
        "    name='Permute'\n",
        ")(x)\n",
        "\n",
        "x = Reshape(\n",
        "    target_shape=(sequence_length, -1), \n",
        "    name='Reshape'\n",
        ")(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5x0WD2NyypQ",
        "outputId": "83912ed3-9056-42e0-9fc3-406161bd1eab"
      },
      "source": [
        "print('Output shape', '(sequence, time, feature)', x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (sequence, time, feature) (None, 313, 1600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0yEMBUZyypQ"
      },
      "source": [
        "Two **bidirectional** **recurrent** layers (Gated Recurrent Units) are used to integrate information from large time window:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSu_rStIyypR"
      },
      "source": [
        "**Recognition** is done with two **fully-connected** layers using information extracted by the previous layers. \n",
        "\n",
        "Layers are wrapped with `TimeDistributed` class to apply layers independently to each time step.\n",
        "\n",
        "**Output layer** (last fully-connected layer) is with sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDzG7ryVzFjS"
      },
      "source": [
        "x = Dense(units=32, kernel_initializer='random_normal', name='FC1' )(x)\n",
        "x = Dropout(rate=0.2, name='FC_DropOut')(x)\n",
        "x = Dense(units=2, kernel_initializer='random_normal', name='Output')(x)\n",
        "output_layer = Activation('sigmoid', name='Output_Activation')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFEXCTksyypR",
        "outputId": "27e60977-819a-48f3-a596-de7a8ea2398e"
      },
      "source": [
        "print('Output shape', '(sequence, time, classes)', output_layer.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (sequence, time, classes) (None, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlYxk1A9yypR"
      },
      "source": [
        "Create a model network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61R1BYqHyypR"
      },
      "source": [
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4vqVymJFjot",
        "outputId": "d70723cd-0490-47f3-ab54-093e5bfbf41f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 513, 313)]        0         \n",
            "                                                                 \n",
            " Input_Reshape (Reshape)     (None, 513, 313, 1)       0         \n",
            "                                                                 \n",
            " Conv1 (Conv2D)              (None, 513, 313, 64)      640       \n",
            "                                                                 \n",
            " Conv1_BatchNorm (BatchNorma  (None, 513, 313, 64)     256       \n",
            " lization)                                                       \n",
            "                                                                 \n",
            " Conv1_Activation (Activatio  (None, 513, 313, 64)     0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " Conv1_Pooling (MaxPooling2D  (None, 102, 313, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv1_DropOut (Dropout)     (None, 102, 313, 64)      0         \n",
            "                                                                 \n",
            " Conv2 (Conv2D)              (None, 102, 313, 64)      36928     \n",
            "                                                                 \n",
            " Conv2_BatchNorm (BatchNorma  (None, 102, 313, 64)     256       \n",
            " lization)                                                       \n",
            "                                                                 \n",
            " Conv2_Activation (Activatio  (None, 102, 313, 64)     0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " Conv2_Pooling (MaxPooling2D  (None, 25, 313, 64)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv2_DropOut (Dropout)     (None, 25, 313, 64)       0         \n",
            "                                                                 \n",
            " Permute (Permute)           (None, 25, 64, 313)       0         \n",
            "                                                                 \n",
            " Reshape (Reshape)           (None, 313, 1600)         0         \n",
            "                                                                 \n",
            " Recurrent_1 (Bidirectional)  (None, 313, 32)          104512    \n",
            "                                                                 \n",
            " Recurrent_2 (Bidirectional)  (None, 32)               4160      \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 32)                1056      \n",
            "                                                                 \n",
            " FC_DropOut (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            " Output_Activation (Activati  (None, 2)                0         \n",
            " on)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 147,874\n",
            "Trainable params: 147,618\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH_Oo3B2yypS"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug-qkl_UyypS"
      },
      "source": [
        "One should evaluate validation data with **same metric** which is used in actual system evaluation with test set \n",
        "\n",
        "For sound event detection, `keras` does not provide any suitable metric (such as *segment-based error rate (ER)* or *f-score (F1)*)\n",
        "\n",
        "Default `keras` training process needs to be modified by halting it after each epoch:\n",
        "- Validation data is evaluated with current model **outside the training process**\n",
        "- Metric values are stored and used to control the training process (e.g. model selection or early stopping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55uHHXOhyypS"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvK2SEdd29JF",
        "outputId": "ad7a4ad2-e081-42d7-b218-55d2e8b2ce76"
      },
      "source": [
        "!pip install colorama"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvmRsV7-yypS"
      },
      "source": [
        "epochs = 100\n",
        "keras_metric = 'accuracy'\n",
        "keras_loss = 'binary_crossentropy'\n",
        "metric_to_monitor = 'ER'\n",
        "external_metrics = {\n",
        "    'ER': 'Error rate',\n",
        "    'F1': 'F-score'\n",
        "}\n",
        "\n",
        "callback_list = [\n",
        "    dcase_util.tfkeras.ProgressLoggerCallback(\n",
        "        epochs=epochs,\n",
        "        metric=keras_metric,\n",
        "        loss=keras_loss,\n",
        "        output_type='console',\n",
        "        show_timing=False,\n",
        "        manual_update=True,     \n",
        "    ),\n",
        "    dcase_util.tfkeras.StasherCallback(\n",
        "        epochs=epochs,\n",
        "        monitor=metric_to_monitor,\n",
        "        initial_delay=50,\n",
        "        manual_update=True,\n",
        "    )\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fihHqQNpyypT",
        "outputId": "006d5f34-77ca-4f5c-a93a-0735823b94dc"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(\n",
        "    loss=keras_loss,\n",
        "    metrics=[keras_metric],\n",
        "    optimizer=Adam(lr=0.001, decay=0.001)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-bm7MIZ2tYW"
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, f1_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hXRMx5OSyypT"
      },
      "source": [
        "epochs = 40\n",
        "# Variable to training history including metrics calculated outside keras\n",
        "history_over_epochs = {\n",
        "    'loss': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': [],\n",
        "    'val_f1': [],\n",
        "}\n",
        "\n",
        "# Do training epoch by epoch\n",
        "for epoch_start in range(0, 40):\n",
        "    epoch_end = epoch_start + 1\n",
        "\n",
        "    # Make sure we have only specified amount of epochs\n",
        "    if epoch_end > epochs:\n",
        "        epoch_end = epochs\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit( x=X_train,        y=Y_train,        validation_data=(X_validation, Y_validation),\n",
        "        callbacks= callback_list,\n",
        "        verbose=0,\n",
        "        initial_epoch=epoch_start,\n",
        "        epochs=epoch_end,        batch_size=8,        shuffle=True\n",
        "    )\n",
        "    \n",
        "    item_probabilities = model.predict(X_validation, batch_size = 8) #(batch_size, 2)\n",
        "    # for item in item_probabilities:\n",
        "    #   for x in item:\n",
        "    #     x = x > 0.5\n",
        "\n",
        "    ground_truth = Y_validation#validation_item['ground_truth']\n",
        "    #print(ground_truth.shape, item_probabilities.shape)\n",
        "    labels_ = np.zeros(item_probabilities.shape)\n",
        "\n",
        "    for label, item in zip(labels_, item_probabilities):\n",
        "      if(item[0] >= 0.5):\n",
        "        label[0] = 1\n",
        "      if(item[1] >= 0.5):\n",
        "        label[1] = 1\n",
        "\n",
        "    f1_score_ = f1_score(ground_truth, labels_, average='micro')\n",
        "    acc = accuracy_score(ground_truth, labels_)\n",
        "    print(\"EPOCH\", epoch_start, \"----------\", \"F1 score\", f1_score_, \"------------\", \"Accuracy\", acc)\n",
        "\n",
        "    # Store metrics\n",
        "    history_over_epochs['loss'].append(history.history['loss'])\n",
        "    history_over_epochs['val_loss'].append(history.history['val_loss'])\n",
        "    history_over_epochs['val_acc'].append(acc)\n",
        "    history_over_epochs['val_f1'].append(f1_score_)\n",
        "    # history_over_epochs['binary_accuracy'].append(history.history['binary_accuracy'])\n",
        "    # history_over_epochs['val_binary_accuracy'].append(history.history['val_binary_accuracy'])\n",
        "\n",
        "    # Manually update callbacks\n",
        "    for callback in callback_list:\n",
        "        if hasattr(callback, 'update'):\n",
        "            callback.update()\n",
        "\n",
        "    # Check if we need to stop training\n",
        "    stop_training = False\n",
        "    for callback in callback_list:\n",
        "        if hasattr(callback, 'stop'):\n",
        "            if callback.stop():\n",
        "                stop_training = True\n",
        "                break\n",
        "\n",
        "    if stop_training:\n",
        "        # Stop the training loop\n",
        "        break\n",
        "\n",
        "# Manually update callbacks\n",
        "for callback in callback_list:\n",
        "    if hasattr(callback, 'close'):\n",
        "        callback.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ylnhe0KZI0r"
      },
      "source": [
        "# model.save(os.path.join('/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project/crnn_gru_sed_weight', 'model_seds_direct_script_30_upto_40_epochs_new.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRhHiGiAyypU"
      },
      "source": [
        "## Best performing model\n",
        "\n",
        "Best performing model was stored during the training process in `StasherCallback`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qc_RHOIyypU"
      },
      "source": [
        "# for callback in callback_list:\n",
        "#     if isinstance(callback, dcase_util.keras.StasherCallback):                \n",
        "#         model.set_weights(callback.get_best()['weights'])       # Fetch the best performing model        \n",
        "#         callback.show()                                         # Show information\n",
        "#         break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mplInOeayypU"
      },
      "source": [
        "Save model and training history:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwx4tcmUK_rc"
      },
      "source": [
        "# # Save training history\n",
        "# dcase_util.files.Serializer().save_cpickle(\n",
        "#     filename=os.path.join('/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project', 'model_cnn_rnn_sed_training_history_30_upto_40_epochs_new.cpickle'),\n",
        "#     data=history_over_epochs\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": true,
        "id": "tLZVuM0eyypU"
      },
      "source": [
        "## Training history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS6BSMz4yypU"
      },
      "source": [
        "hist = dcase_util.files.Serializer().load_cpickle(filename=os.path.join('/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project', 'model_cnn_rnn_sed_training_history_upto_10_epochs.cpickle'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqXfVfHUL409",
        "outputId": "6bd73d95-94a0-4add-c914-37e567be00b3"
      },
      "source": [
        "print(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [[0.6190886497497559], [0.564346194267273], [0.5319881439208984], [0.5088754296302795], [0.4856886863708496], [0.4726979732513428], [0.47057390213012695], [0.5011380314826965], [0.4881892502307892], [0.47413286566734314]], 'val_loss': [[0.6866677403450012], [0.6893298625946045], [0.7021951079368591], [0.7254590392112732], [0.7537027597427368], [0.7206918001174927], [0.745861828327179], [0.6805738210678101], [0.7056502103805542], [0.682929515838623]], 'val_er': [1.1379310344827587, 1.103448275862069, 1.206896551724138, 1.2413793103448276, 0.9770114942528736, 0.9885057471264368, 0.9195402298850575, 1.2413793103448276, 1.2413793103448276, 1.0459770114942528], 'val_f1': [0.3421052631578948, 0.5142857142857142, 0.6137184115523466, 0.6120996441281138, 0.5361702127659573, 0.5485232067510549, 0.5374449339207049, 0.592057761732852, 0.6071428571428571, 0.5702811244979921], 'binary_accuracy': [[0.687228262424469], [0.7013139724731445], [0.7080639600753784], [0.7212162613868713], [0.7449852824211121], [0.7537132501602173], [0.7534298300743103], [0.7113685011863708], [0.7306349277496338], [0.7461457848548889]], 'val_binary_accuracy': [[0.7022364139556885], [0.6400958299636841], [0.5228434801101685], [0.5036741495132446], [0.5178913474082947], [0.5126197934150696], [0.49169328808784485], [0.5490415096282959], [0.5306709408760071], [0.5801916718482971]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "tC-Hm72eyypV"
      },
      "source": [
        "epochs = range(1, len(hist['loss']) + 1)\n",
        "fig = plt.figure(figsize=(19,8))\n",
        "\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(epochs, hist['loss'], color='red', linewidth=3, label='Training loss')\n",
        "plt.plot(epochs, hist['val_loss'], color='green', linewidth=3, label='Validation loss')\n",
        "#plt.fill_between(epochs, numpy.squeeze(numpy.array(hist['val_loss'])), color='#6aa84f', linewidth=3, label='Validation loss')\n",
        "plt.ylabel('Loss', fontsize=18)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "panel = plt.gca()\n",
        "panel.set_xlim([1,len(hist['loss']) + 1])\n",
        "panel.get_xaxis().set_visible(True)\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(epochs, hist['val_er'], color='blue', linewidth=3, label='Validation Error rate')\n",
        "plt.axhline(y=1, color='red', linestyle='-', linewidth=5, alpha=0.2)\n",
        "plt.ylabel('Error rate', fontsize=18)\n",
        "er_min_index = numpy.argmin(hist['val_er'])\n",
        "plt.axhline(hist['val_er'][er_min_index], color='green', linestyle='-', linewidth=5, alpha=0.5) #'o', markersize=10, color='red')\n",
        "plt.annotate('Minimum achieved ER value', xy=(len(hist['loss']),hist['val_er'][er_min_index]-0.15), fontsize=14, ha='right')\n",
        "plt.annotate('ER=1.0', xy=(len(hist['loss']),1+0.05), fontsize=14, ha='right')\n",
        "panel = plt.gca()\n",
        "panel.set_xlim([1,len(hist['loss']) + 1])\n",
        "panel.get_xaxis().set_visible(True)\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(epochs, hist['val_f1'], color='black', linewidth=3, label='F-score')\n",
        "plt.ylabel('F-score', fontsize=18)\n",
        "plt.xlabel('Epochs', fontsize=18)\n",
        "panel = plt.gca()\n",
        "panel.set_xlim([1,len(hist['loss']) + 1])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "cxrRUI1EyypV"
      },
      "source": [
        "# Testing stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtYxAku1yypV"
      },
      "source": [
        "#model = keras.models.load_model('/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project/crnn_gru_sed_weight/model_seds_direct_script_upto_10_epochs_new.h5') # Load model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": true,
        "id": "_PlWIVtLyypZ"
      },
      "source": [
        "## Going through all test material"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8HdaXiQ1dUj"
      },
      "source": [
        "def binarization(self, probabilities, binarization_type='global_threshold', threshold=0.5, time_axis=1):\n",
        "        \"\"\"Binarization\n",
        "        Parameters\n",
        "        ----------\n",
        "        probabilities : numpy.ndarray\n",
        "            Probabilities to be binarized\n",
        "        binarization_type : str ('global_threshold', 'class_threshold', 'frame_max')\n",
        "        threshold : float\n",
        "            Binarization threshold, value of the threshold are replaced with 1 and under with 0.\n",
        "            Default value 0.5\n",
        "        time_axis : int\n",
        "            Axis index for the frames\n",
        "            Default value 1\n",
        "        Raises\n",
        "        ------\n",
        "        AssertionError:\n",
        "            Unknown binarization_type\n",
        "        Returns\n",
        "        -------\n",
        "        numpy.ndarray\n",
        "            Binarized data\n",
        "        \"\"\"\n",
        "\n",
        "        if binarization_type not in ['global_threshold', 'class_threshold', 'frame_max']:\n",
        "            message = '{name}: Unknown frame_binarization type [{type}].'.format(\n",
        "                name=self.__class__.__name__,\n",
        "                type=binarization_type\n",
        "            )\n",
        "\n",
        "            self.logger.exception(message)\n",
        "            raise AssertionError(message)\n",
        "\n",
        "        # Get data_axis\n",
        "        if time_axis == 0:\n",
        "            data_axis = 1\n",
        "        else:\n",
        "            data_axis = 0\n",
        "\n",
        "        if binarization_type == 'global_threshold':\n",
        "            return numpy.array(probabilities >= threshold, dtype=int)\n",
        "\n",
        "        elif binarization_type == 'class_threshold' and isinstance(threshold, list):\n",
        "            data = []\n",
        "            for class_id, class_threshold in enumerate(threshold):\n",
        "                if data_axis == 0:\n",
        "                    data.append(numpy.array(probabilities[class_id, :] >= class_threshold, dtype=int))\n",
        "\n",
        "                elif data_axis == 1:\n",
        "                    data.append(numpy.array(probabilities[:, class_id] >= class_threshold, dtype=int))\n",
        "\n",
        "            if data_axis == 0:\n",
        "                return numpy.vstack(data)\n",
        "\n",
        "            elif data_axis == 1:\n",
        "                return numpy.vstack(data).T\n",
        "\n",
        "        elif binarization_type == 'frame_max':\n",
        "            if data_axis == 0:\n",
        "                return numpy.array((probabilities / numpy.max(probabilities, axis=0)) == 1, dtype=int)\n",
        "\n",
        "            elif data_axis == 1:\n",
        "                return numpy.array((probabilities.T / numpy.max(probabilities, axis=1)).T == 1, dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU7ZOvWlyypa"
      },
      "source": [
        "res = dcase_util.containers.MetaDataContainer(filename=os.path.join(data_storage_path, 'results_sed.csv'))\n",
        "\n",
        "audio_folder_name = '/content/drive/MyDrive/5th_sem/Ee603_mlsp/Project/validation_data/validation_wavs'\n",
        "for audio_filename in os.listdir(audio_folder_name):\n",
        "    # Load features\n",
        "    # features = get_feature_matrix(item.filename)\n",
        "    # features_sequenced = data_sequencer.sequence(features).data\n",
        "    # input_data = numpy.moveaxis(features_sequenced, 2, 0) # Rearrange axes => (sequence, feature vector, time)\n",
        "    audio_path = os.path.join(audio_folder_name, audio_filename)\n",
        "    features, hop_length_seconds = get_feature_matrix_script_features(audio_path)\n",
        "    #features = features[:,:500]\n",
        "    input_data = features.reshape(1, features.shape[0], features.shape[1])\n",
        "\n",
        "\n",
        "    # Get network output\n",
        "    item_probabilities_seq = model.predict(x=input_data)        # Get per frame probabilities in sequences (3D matrix)\n",
        "    item_probabilities = numpy.vstack(item_probabilities_seq)   # Merge sequences together (2D matrix)\n",
        "\n",
        "    # Event activity\n",
        "    event_activity = dcase_util.data.ProbabilityEncoder().binarization(\n",
        "        probabilities=item_probabilities,\n",
        "        binarization_type='global_threshold',\n",
        "        threshold=0.5\n",
        "    )\n",
        "    current_estimated = dcase_util.containers.MetaDataContainer()\n",
        "    for event_id, event_label in enumerate(['speech', 'music']):\n",
        "        # Convert active frames into segments and translate frame indices into timestamps\n",
        "        event_segments = dcase_util.data.DecisionEncoder().find_contiguous_regions(\n",
        "            activity_array=event_activity[:, event_id]\n",
        "        ) * 0.03194888178\n",
        "\n",
        "        # Form event items\n",
        "        for event in event_segments:\n",
        "            current_estimated.append(\n",
        "                {\n",
        "                    'filename': audio_filename,\n",
        "                    'onset': event[0],\n",
        "                    'offset': event[1],\n",
        "                    'event_label': event_label\n",
        "                }\n",
        "            )\n",
        "            \n",
        "        # Merge events together from same class which are within 100ms\n",
        "        current_estimated = current_estimated.process_events(minimum_event_gap=0.5)\n",
        "        # Remove events which are < 100ms \n",
        "        current_estimated = current_estimated.process_events(minimum_event_length=0.5)\n",
        "        \n",
        "    # Store result into results container\n",
        "    res += current_estimated\n",
        "    \n",
        "# Save results container\n",
        "res.save().show(mode='print')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}